<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Value functions as Lagrange multiplier estimates &mdash; Graduate Descent</title>
  <meta name="author" content="Tim Vieira">

  <link href="/blog/atom.xml" type="application/atom+xml" rel="alternate"
        title="Graduate Descent Atom Feed" />





  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta name="robots" content="noindex, nofollow" />

    <link href="../favicon.png" rel="icon">

  <link href="../theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="../">Graduate Descent</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/blog/atom.xml" rel="subscribe-atom">Atom</a></li>
</ul>


<ul class="main-navigation">
    <li><a href="http://timvieira.github.io/">About</a></li>
    <li><a href="/blog/index.html">Archive</a></li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Value functions as Lagrange multiplier estimates</h1>
    <p class="meta">
<time datetime="2018-03-16T00:00:00-04:00" pubdate>Mar 16, 2018</time>    </p>
</header>

  <div class="entry-content"><p><a href="https://en.wikipedia.org/wiki/Bellman_equation">Value functions</a>, or some
variant thereof, are key concept in sequential decision-making tasks (e.g.,
reinforcement learning, planning under uncertaintly, and optimal control).  They
generally regarded as (somewhat intuitive) definitions that seem to help solve
the decision-making problem.  In this post, I will give an account of value
functions as Lagrange multiplier estimates for a specific formulation of the
policy-search problem in reinforcement learning - I believe this story
generalize to the other cases, but I haven't worked it out formally.  This
connection is pretty cool and is closely related to my previous post on
<a href="http://timvieira.github.io/blog/post/2017/08/18/backprop-is-not-just-the-chain-rule/">backpropagation and Lagrangians</a>.</p>
<!--
They are a mathematical operationalization of the idea that

> “Life can only be understood backwards; but it must be lived forwards.”
>
> ― [Søren Kierkegaard](https://www.goodreads.com/quotes/6812-life-can-only-be-understood-backwards-but-it-must-be)
-->

<p><strong>The setup</strong>: Let <span class="math">\(M = \langle S, A, p_0(s), p(s' \mid s, a), r(s,a), \gamma \rangle\)</span>
be a Markov decision process over states <span class="math">\(S\)</span> and actions <span class="math">\(A\)</span> with <span class="math">\(0 &lt; \gamma &lt; 1\)</span>.  Let <span class="math">\(p_0(s)\)</span> be a
distribution over initial states and <span class="math">\(p(s' \mid s, a)\)</span> be a transition kernel
that describes how the next state <span class="math">\(s'\)</span> evolve from current state <span class="math">\(s\)</span> given an action <span class="math">\(a\)</span>
from a policy <span class="math">\(\pi(a \mid s)\)</span>.  Lastly, let <span class="math">\(r(s,a)\)</span> denote the immediate reward of taking action <span class="math">\(a\)</span> in state <span class="math">\(s\)</span>. The utility of a policy <span class="math">\(\pi\)</span> is typically measure as the long-term,
<span class="math">\(\gamma\)</span>-discounted reward
</p>
<div class="math">$$
U(\pi) \overset{\text{def}}{=} \mathbb{E}\left[  \sum_{t=0}^\infty \gamma^t \!\cdot\! r(s,a) \right]
$$</div>
<p>where the randomness in the expecation is take over trajectories, <span class="math">\(\langle
\langle s_t, a_t, r_t \rangle \rangle_{t=0}^\infty\)</span>.  Don't worry too much about
the infinite summation, we will now replace it with something much more
computation friendly.</p>
<p><strong>The policy search problem:</strong> Here we write the policy search problem as a
constrained optimization problem.  We exploit an important rewrite of <span class="math">\(U(\pi)\)</span>
as the expectation an expectation over an occupancy measure over states rather
than an expectation over infinitely long trajectories.</p>
<div class="math">$$
\underset{\pi, \delta}{\textrm{maximize }} U = \frac{1}{1-\gamma}\sum_{s,a} r(s,a) \cdot \delta(s) \cdot \pi(a|s)
$$</div>
<p><em>subject to</em></p>
<ul>
<li><span class="math">\(\pi\)</span> is a valid conditional probability distribution</li>
</ul>
<div class="math">$$
\textstyle\sum_a \pi(a | s) = 1 \quad\text{for all } s \in S
$$</div>
<div class="math">$$
\pi(a | s) \ge 0 \quad\text{for all } s \in S, a \in A
$$</div>
<ul>
<li><span class="math">\(\delta\)</span> is <span class="math">\(\pi\)</span>'s occupancy measure (<strong>footnote</strong>: Alternatively, we can
   think of <span class="math">\(\delta\)</span> as <span class="math">\(\pi\)</span>'s stationary distribution if we regard
   <span class="math">\((1-\gamma)\)</span> as the probability of restarting the Markov chain (i.e.,
   sampling the next state from a mixture of <span class="math">\(p_0(s')\)</span> with probability
   <span class="math">\((1-\gamma)\)</span> and from <span class="math">\(p(s' \mid s,a)\)</span> with probability <span class="math">\(\gamma\)</span>).)</li>
</ul>
<div class="math">$$
\delta(s') = (1-\gamma) \cdot p_0(s') + \gamma \cdot \sum_{s,a} \delta(s) \cdot \pi(a|s) \cdot p(s'|s,a)\quad\text{for all }s' \in S
$$</div>
<div class="math">$$
\sum_{s} \delta(s) = 1
$$</div>
<div class="math">$$
\delta(s) \ge 0 \quad\text{for all }s
$$</div>
<p>Written as above, this optimization problem is a quadratic program with
quadractic equality constraints.  Quadratic equality constraints can encode
nonconvex constraints, which are generally NP-Hard to solve.  (<strong>footnote</strong>: To
see why, consider the constraint <span class="math">\(x \cdot (x - 1) = 0\)</span>, this constraint has
exactly two solutions <span class="math">\(x \in \{0, 1\}\)</span>.  In other words, it is an encoding of
binary variables, and thus can be used to solve NP-hard problems.)</p>
<h2>Lagrangian</h2>
<p>We can write out the Lagrangian for this optimization problem</p>
<div class="math">$$
\begin{eqnarray*}
\mathcal{L}(\delta, \pi, \lambda, \sigma, \zeta, \eta)
&amp;=&amp; \sum_{s,a} r(s,a) \delta(s) \pi(a|s)\\
&amp;&amp; + \sum_{s'} \lambda(s') \delta(s')  - \sum_{s,a} \lambda(s') \delta(s) \pi(a|s) p(s'|s,a)\\
&amp;&amp; + \sum_s \sigma(s)  - \sum_a \sigma(s) \pi(a | s)\\
&amp;&amp; + \sum_{s,a} \zeta(s,a) \pi(a | s) \\
&amp;&amp; + \sum_{s} \eta(s) \delta(a | s)
\end{eqnarray*}
$$</div>
<p>TODO: What does it mean to be a Lagrange multiplier <em>estimate</em></p>
<p>Now, let's solve for <span class="math">\(\nabla \mathcal{L} = 0\)</span> under each chunk of parameters.</p>
<div class="math">$$
\begin{eqnarray*}
\frac{\partial \mathcal{L}}{\partial \delta(s^*)}
&amp;=&amp;
\sum_a r(s^*,a) \pi(a \mid s^*)
+ \sum_{s'} \lambda(s') (1(s' = s^*)
- \sum_{a} \delta(s^*) \pi(a \mid s^*) p(s' \mid s^*, a))\\
\end{eqnarray*}
$$</div>
<div class="math">$$
\begin{eqnarray*}
\frac{\partial \mathcal{L}}{\partial \pi(a^* \mid s^*)}
&amp;=&amp;
r(s^*,a^*) \delta(s^*)
- \sum_{s'} \lambda(s') \delta(s^*) p(s'|s^*,a^*)
 - \sum_a \sigma(s^*)
 + \zeta(s^*,a^*)
\end{eqnarray*}
$$</div>
<h2>Linear programming re-formulation</h2>
<p>Manne (1960), came up with a very clever trick which reformulates this
optimization into a linear programming problem.  The trick is to "flatten" the
optimization of <span class="math">\(\pi\)</span> and <span class="math">\(\delta\)</span>, by optimizing over their product <span class="math">\(\mu(s,a)
\overset{\text{def}}{=} \pi(a \mid s) \cdot \delta(s)\)</span> instead.  We can recover
our original variables as <span class="math">\(\delta(s) = \sum_a \mu(s,a)\)</span> and <span class="math">\(\pi(a \mid s) =
\mu(s,a) / \delta(s)\)</span>.  If every <span class="math">\(\delta(s)=0\)</span> the choice for <span class="math">\(\pi(a \mid s)\)</span> is
an arbitrary distribution over <span class="math">\(a\)</span>.</p>
<div class="math">$$
\underset{\pi}{\textrm{maximize }} \frac{1}{1-\gamma}\sum_{s,a} r(s,a) \cdot \mu(s, a)
$$</div>
<p><em>subject to</em></p>
<ul>
<li><span class="math">\(\mu\)</span> is a valid occupancy measure over state-actions pairs</li>
</ul>
<div class="math">$$
\sum_{a'} \mu(s',a') = (1-\gamma) \cdot p_0(s') + \gamma \cdot \sum_{s,a} \mu(s,a) \cdot p(s'|s,a)\quad\text{for all }s' \in S
$$</div>
<div class="math">$$
\mu(s, a) \ge 0 \quad\text{for all }s, a
$$</div>
<p>It turns out that explicit sum-to-one constraint (i.e., <span class="math">\(\sum_{s,a} \mu(s,a) =
1\)</span>) is not necessary because solutions to the linear constraints will are
already normalized.</p>
<p><strong>TODO</strong> Formulate the Lagrangian.  Take its derivatives.</p>
<p><strong>TODO</strong> Take the LP dual, note that it is exactly the optimal value function
  problem.</p>
<p><strong>TODO</strong> Block-coordinate method - is policy iteration.  Just like my backprop
  post, we can take any fixed policy and estimate the Lagrange mulipliers by
  setting the gradient of the Lagrangian wrt <span class="math">\(V\)</span> equal to zero given what every
  <span class="math">\(\pi\)</span> is.</p>
<h2>Connections in graphical models</h2>
<p>The concept of a value function is not limited to RL: value functions arise in
the dynamic programming solutions to many other problems.</p>
<p>Building on
<a href="http://timvieira.github.io/blog/post/2017/08/18/backprop-is-not-just-the-chain-rule/">Vieira (2017)</a>,
the gradient estimates provided by backpropagation can be viewed as Lagrange
muliplier estimates in a particular formulation of an optimization problem with
intermediate variables that are defined by equality constraints on intermediate
quantities.</p>
<p>Consider the case of the forward-backward algorithm for linear-chain CRFs or
HMMs.  As detailed in
<a href="https://www.cs.jhu.edu/~jason/papers/eisner.spnlp16.pdf">Eisner (2016)</a>, the
backward algorithm and the outside algorithm are <em>precisely</em> the result of
backpropgation on the forward algorithm and inside algorithm respectively.</p>
<p>Much like the MDP setting, the backward algorithm and outside algorithm are
often viewed as some useful quantities.  However, when viewed as the result of
backpropagation it not only deepens our understanding of the connection, but
also establishes a bridge to the rich theory that underlies automatic
differentiation.  This connection tells us important things about the time and
space complexity of algorithms for computing these quantities and even better
gives us a recipe for efficiently computing these quantities backward/outside
quantities.</p>
<p>This connection extends to marginal inference in Bayesian networks more
generally <a href="https://dl.acm.org/citation.cfm?id=765570">Darwiche (2003)</a>.</p>
<blockquote>
<p>Adnan Darwiche. <a href="https://dl.acm.org/citation.cfm?id=765570">A differential approach to inference in Bayesian networks</a>. Journal of the Association for Computing Machinery, 50(3):280–305, 2003.</p>
</blockquote>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        Tim Vieira
    </span>
  </span>
<time datetime="2018-03-16T00:00:00-04:00" pubdate>Mar 16, 2018</time>  <span class="categories">
    <a class='category' href='../category/misc.html'>misc</a>
  </span>
  <span class="categories">
    <a class="category" href="../tag/rl.html">rl</a>,    <a class="category" href="../tag/calculus.html">calculus</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="../post/2019/06/11/faster-reservoir-sampling-by-waiting/">Faster reservoir sampling by waiting</a>
      </li>
      <li class="post">
          <a href="../post/2019/04/20/the-likelihood-ratio-gradient/">The likelihood-ratio gradient</a>
      </li>
      <li class="post">
          <a href="../post/2019/04/19/steepest-ascent/">Steepest ascent</a>
      </li>
      <li class="post">
          <a href="../post/2018/03/16/black-box-optimization/">Black-box optimization</a>
      </li>
      <li class="post">
          <a href="../post/2017/08/18/backprop-is-not-just-the-chain-rule/">Backprop is not just the chain rule</a>
      </li>
    </ul>
  </section>

  <section>
  <h1>Tags</h1>
    <a href="../tag/sampling.html">sampling</a>,    <a href="../tag/reservoir-sampling.html">reservoir-sampling</a>,    <a href="../tag/gumbel.html">Gumbel</a>,    <a href="../tag/optimization.html">optimization</a>,    <a href="../tag/rl.html">rl</a>,    <a href="../tag/machine-learning.html">machine-learning</a>,    <a href="../tag/notebook.html">notebook</a>,    <a href="../tag/calculus.html">calculus</a>,    <a href="../tag/automatic-differentiation.html">automatic-differentiation</a>,    <a href="../tag/statistics.html">statistics</a>,    <a href="../tag/testing.html">testing</a>,    <a href="../tag/counterfactual-reasoning.html">counterfactual-reasoning</a>,    <a href="../tag/importance-sampling.html">importance-sampling</a>,    <a href="../tag/datastructures.html">datastructures</a>,    <a href="../tag/algorithms.html">algorithms</a>,    <a href="../tag/rant.html">rant</a>,    <a href="../tag/decision-making.html">decision-making</a>,    <a href="../tag/hyperparameter-optimization.html">hyperparameter-optimization</a>,    <a href="../tag/misc.html">misc</a>,    <a href="../tag/numerical.html">numerical</a>,    <a href="../tag/crf.html">crf</a>,    <a href="../tag/deep-learning.html">deep-learning</a>,    <a href="../tag/structured-prediction.html">structured-prediction</a>,    <a href="../tag/visualization.html">visualization</a>  </section>



</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2014&ndash;2019  Tim Vieira &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="../theme/js/modernizr-2.0.js"></script>
  <script src="../theme/js/ender.js"></script>
  <script src="../theme/js/octopress.js" type="text/javascript"></script>
  <script type="text/javascript">
    var disqus_shortname = 'graduatedescent';
    var disqus_identifier = '/drafts/value-functions-as-lagrange-multiplier-estimates.html';
    var disqus_url = '../drafts/value-functions-as-lagrange-multiplier-estimates.html';
    var disqus_title = 'Value functions as Lagrange multiplier estimates';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-8781169-1', 'auto');
  ga('send', 'pageview');
</script>

  
</body>
</html>